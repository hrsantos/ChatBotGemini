{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13Xaaj0-CF7ihDLI21tnArJZ7uLm4wUzJ",
      "authorship_tag": "ABX9TyOYXjTlnEUjrwoTtWUNC2JN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hrsantos/ChatBotGemini/blob/main/Chat_Bot_Aula_4_Gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do Google Gemini"
      ],
      "metadata": {
        "id": "nZiwQ8MED-WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "iDALLBf0D3Dt"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o Python SDK\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configurando a api key do Google Gemini\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "3KlND22kEQa3"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis\n",
        "\n",
        "Nota: versões PRO só trabalham com inputs de textos, já as versões PRO-VISION trabalham com imputs de textos, imagens e vídeos ao mesmo tempo"
      ],
      "metadata": {
        "id": "aT6zIfWMEm0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "c3V3BlXaEl3l",
        "outputId": "1b2042d0-2d45-489a-e041-ca0418fc6c73"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando os parâmetros para a geração das respostas"
      ],
      "metadata": {
        "id": "sANSWiugJS6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1, # fixa a possibilidade de resposta a apenas um opção\n",
        "    \"temperature\": 0.5, # controla o nível de aleatoriedade na construção da resposta gerada pelo Gemini\n",
        "}"
      ],
      "metadata": {
        "id": "hjDhfp-hIKVU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando os parâmetros de segurança das respostas\n",
        "\n",
        "Essas configurações permitem parametrizar o nível de permissão para a geração de respostas com conteúdo sensível"
      ],
      "metadata": {
        "id": "wdbfHIz0KE6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# opções de valores de parâmetros disponíveis: BLOCK_NONE, BLOCK_FEW, BLOCK_SOME, BLOCK_MOST,\n",
        "# Esses parâmetros controlam o nível de liberdade da IA na geração das respostas\n",
        "\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "4DfHsWT4KDtM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iniciando o modelo\n",
        "\n",
        "Nessa etapa, escolhemos com qual versão dos modelos iremos trabalhar e também informamos os demais parâmetros que configuramos anteriormente"
      ],
      "metadata": {
        "id": "fLmB3vJHMwDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\", generation_config=generation_config, safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "DJGzEO-k1UZW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do chatbot\n",
        "\n",
        "Criamos uma variável que receberá o método de inicialização de um chatbot com uma lista de histórico da conversa vazia"
      ],
      "metadata": {
        "id": "Imso5kBYbljJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "DF_SFBejbtl-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o input de entrada de dados"
      ],
      "metadata": {
        "id": "zTpocfDlc6CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Olá! em que posso ajudar? \")\n",
        "\n",
        "while (prompt != \"fim\"):\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  prompt = input(\"Ainda precisa de ajuda? Escreva o que você deseja.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "uVIJaekbds-1",
        "outputId": "04884d53-8bb7-49cc-80ac-847e2e803cb3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Olá! em que posso ajudar? Qual a origem da expressão \"Hello World\"?\n",
            "Resposta:  A origem da expressão \"Hello World\" é atribuída ao programador Brian Kernighan, que a usou em um exemplo de código em seu livro \"A Linguagem de Programação C\" (1978).\n",
            "\n",
            "O livro foi um dos primeiros a ensinar a linguagem de programação C e o exemplo \"Hello World\" foi projetado para ser um programa simples e fácil de entender para iniciantes. O programa simplesmente imprime a mensagem \"Hello World\" na tela.\n",
            "\n",
            "Desde então, a expressão \"Hello World\" tornou-se um programa de exemplo comum usado em tutoriais e livros de programação para demonstrar os fundamentos de uma nova linguagem de programação. \n",
            "\n",
            "Ainda precisa de ajuda? Escreva o que você deseja.fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melhorando a visualização\n",
        "# Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown (f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('---------------------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "14xyZ3-GnGGN",
        "outputId": "e8d0cb1b-0ad6-4471-9f58-044d9117ec1d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual a origem da expressão \"Hello World\"?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: A origem da expressão \"Hello World\" é atribuída ao programador Brian Kernighan, que a usou em um exemplo de código em seu livro \"A Linguagem de Programação C\" (1978).\n> \n> O livro foi um dos primeiros a ensinar a linguagem de programação C e o exemplo \"Hello World\" foi projetado para ser um programa simples e fácil de entender para iniciantes. O programa simplesmente imprime a mensagem \"Hello World\" na tela.\n> \n> Desde então, a expressão \"Hello World\" tornou-se um programa de exemplo comum usado em tutoriais e livros de programação para demonstrar os fundamentos de uma nova linguagem de programação."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}